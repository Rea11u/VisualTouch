import cv2
import numpy as np
import time
import concurrent.futures


# Чтение видео
def video_import(path):
    cap = cv2.VideoCapture(path)
    img_list = []
    while cap.isOpened():
        ret, frame = cap.read()
        if isinstance(frame, np.ndarray):
            img_list.append(frame)
        else:
            print('Видео считано')
            break
    cap.release()
    return img_list


# Обработка видео через color_noise и исправляем цветовые каналы
diffGreen = 0
diffBlue = 0
diffRed = 0

def color_noise(image):
    start = time.time()
    blured_img = cv2.blur(image, (3, 3))
    gray_orig = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray_blured = cv2.cvtColor(blured_img, cv2.COLOR_BGR2GRAY)

    bin_orig = cv2.adaptiveThreshold(gray_orig, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)
    bin_blured = cv2.adaptiveThreshold(gray_blured, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)

    difference = cv2.bitwise_xor(bin_orig, bin_blured, mask=None)
    nonZero = cv2.countNonZero(difference)
    allPixels = bin_orig.shape[0] * bin_orig.shape[1]
    noise = nonZero / allPixels * 100

    red_noise(image.copy(), bin_blured)
    green_noise(image.copy(), bin_blured)
    blue_noise(image.copy(), bin_blured)

    nonZeroGreen = cv2.countNonZero(diffGreen)
    nonZeroBlue = cv2.countNonZero(diffBlue)
    nonZeroRed = cv2.countNonZero(diffRed)

    if nonZeroGreen >= nonZeroBlue:
        if nonZeroGreen >= nonZeroRed:
            channel = 'green'
        else:
            channel = 'red'
    elif nonZeroBlue >= nonZeroRed:
        channel = 'blue'
    else:
        channel = 'red'

    finishCN = time.time()
    print("время color_noise", finishCN - start)
    return ([channel, noise], finishCN - start)


# Функция выделения шума в цветовом канале изображения
def red_noise(image, bin_blrd):
    red_channel = image[:, :, 2]
    bin_red = cv2.adaptiveThreshold(red_channel, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)
    global diffRed
    diffRed = cv2.bitwise_xor(bin_red, bin_blrd)


def green_noise(image, bin_blrd):
    green_channel = image[:, :, 1]
    bin_green = cv2.adaptiveThreshold(green_channel, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)
    global diffGreen
    diffGreen = cv2.bitwise_xor(bin_green, bin_blrd)


def blue_noise(image, bin_blrd):
    blue_channel = image[:, :, 0]
    bin_blue = cv2.adaptiveThreshold(blue_channel, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)
    global diffBlue
    diffBlue = cv2.bitwise_xor(bin_blue, bin_blrd)


# Функция по очищению шума с помощью морфологий
def morph_transform(noise, image):
    start = time.time()
    if image.shape[0] * image.shape[1] > 500 * 500:
        if noise <= 10:
            kernel = np.ones((2, 2), np.uint8)
            iter = 1
        elif 10 < noise <= 20:
            kernel = npones((3, 3), np.uint8)
            iter = 2
        else:
            kernel = np.ones((2, 2), np.uint8)
            iter = 1

        red_channel = image[:, :, 2]
        green_channel = image[:, :, 1]
        blue_channel = image[:, :, 0]

        dilation_red = cv2.dilate(red_channel, kernel, iterations=iter)
        dilation_green = cv2.dilate(green_channel, kernel, iterations=iter)
        dilation_blue = cv2.dilate(blue_channel, kernel, iterations=iter)

        erosion_red = cv2.erode(dilation_red, kernel, iterations=1)
        erosion_green = cv2.erode(dilation_green, kernel, iterations=1)
        erosion_blue = cv2.erode(dilation_blue, kernel, iterations=1)

        transformed_image = image.copy()
        transformed_image[:, :, 2] = erosion_red
        transformed_image[:, :, 1] = erosion_green
        transformed_image[:, :, 0] = erosion_blue
    else:
        transformed_image = image
    finishMT = time.time()
    print("время morph_transform", finishMT - start)
    return transformed_image, finishMT - start


# Функция убирает шум с помощью гауссового размытия
def gaussian_transform(noise, channel, image):
    start = time.time()
    transformed_image = image.copy()

    size_param = 0 if image.shape[0] * image.shape[1] > 500 * 500 else 4

    if noise <= 10:
        rep = 1
        size = 9 - size_param
    elif 10 < noise <= 20:
        rep = 2
        size = 11 - size_param
    else:
        rep = 3
        size = 13 - size_param

    if channel == 'red':
        red_channel = image[:, :, 2]
        gaussian_blur = cv2.GaussianBlur(red_channel, (size, size), rep)
        transformed_image[:, :, 2] = gaussian_blur
    elif channel == 'green':
        green_channel = image[:, :, 1]
        gaussian_blur = cv2.GaussianBlur(green_channel, (size, size), rep)
        transformed_image[:, :, 1] = gaussian_blur
    elif channel == 'blue':
        blue_channel = image[:, :, 0]
        gaussian_blur = cv2.GaussianBlur(blue_channel, (size, size), rep)
        transformed_image[:, :, 0] = gaussian_blur

    finishGT = time.time()
    print("время gaussian_transform", finishGT - start)
    return transformed_image, finishGT - start


def check_file_exists(path):
    try:
        with open(path, 'r'):
            pass
    except FileNotFoundError:
        print("Файл не найден.")
        return False
    return True


def create_video(output_path, image_list):
    if not image_list:
        print("Список изображений пуст. Невозможно создать видео.")
        return

    width = image_list[0].shape[1]
    height = image_list[0].shape[0]

    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'DIVX'), 30, (width, height))

    for image in image_list:
        out.write(image)
    out.release()
    print('Видео сохранено по пути:', output_path)


def process_frame(frame):
    noise_info, _ = color_noise(frame)
    morph_transformed, _ = morph_transform(noise_info[1], frame)
    final_frame, _ = gaussian_transform(noise_info[1], noise_info[0], morph_transformed)
    return final_frame


# Пример использования
video_path = r"C:\Users\Really\Desktop\Auth2.mp4"
output_path = r"C:\Users\Really\Desktop\ResultVideo\Result

video_frames = video_import(video_path)

start_time = time.time()
with concurrent.futures.ThreadPoolExecutor() as executor:
    processed_frames = list(executor.map(process_frame, video_frames))

create_video(output_path, processed_frames)
print("Время выполнения:", time.time() - start_time)
